{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfc3088-89be-4083-989d-3cbc3a471847",
   "metadata": {},
   "source": [
    "### Infer single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "54616499-4aa6-4106-b05f-5b2f8e508329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['PYTHONPATH'] = '/home/qihao/MelodyBot'\n",
    "sys.path.append('/home/qihao/MelodyBot')\n",
    "import pickle\n",
    "import traceback\n",
    "import random\n",
    "import subprocess\n",
    "import torch.cuda\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.earlystopping.protocols import EarlyStopping\n",
    "from utils.test_dataloder import *\n",
    "import datetime\n",
    "from utils.get_time import get_time\n",
    "import gc, copy\n",
    "from tqdm import tqdm\n",
    "from utils.warmup import *\n",
    "import torch.nn.functional as F\n",
    "from models.bartmodel_octuple import Bart\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import prosodic as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "4e696daa-1c57-4b35-8aad-3c65bde8fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "7b52e9a3-3226-4ca6-982b-c357a3e23789",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = 'checkpoint_20240406:190014_lr_5e-05'\n",
    "# ckpt_name = 'checkpoint_20240406:144930_lr_5e-05'\n",
    "ckpt_dir = f'/data1/qihao/cs6207/octuple/checkpoints/{ckpt_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2303fc-2852-44c4-8955-85b5f7c37874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "da90aa88-dabb-44e9-8df1-6215d474e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_keys = ['strength', 'length', 'phrase']\n",
    "tgt_keys = ['bar', 'pos', 'token', 'dur', 'phrase']\n",
    "\n",
    "binary_dir = '/data1/qihao/cs6207/octuple/binary'\n",
    "words_dir = '/data1/qihao/cs6207/octuple/binary/words' ## pretrain\n",
    "# words_dir = '/data1/qihao/cs6207/octuple/binary_909/words' ## 909\n",
    "hparams = {\n",
    "    'batch_size': 1,\n",
    "    'word_data_dir': words_dir,\n",
    "    'sentence_maxlen': 512,\n",
    "    'hidden_size': 768,\n",
    "    'n_layers': 6,\n",
    "    'n_head': 8,\n",
    "    'pretrain': '',\n",
    "    'lr': 5.0e-5,\n",
    "    'optimizer_adam_beta1': 0.9,\n",
    "    'optimizer_adam_beta2': 0.98,\n",
    "    'weight_decay': 0.001,\n",
    "    'patience': 5,\n",
    "    'warmup': 2500,\n",
    "    'lr': 5.0e-5,\n",
    "    'checkpoint_dir': '/home/qihao/CS6207/octuple/checkpoints',\n",
    "    'drop_prob': 0.2,\n",
    "    'total_epoch': 1000,\n",
    "    'infer_batch_size': 1,\n",
    "    'temperature': 1.6,\n",
    "    'topk': 5,\n",
    "    'prompt_step': 1,\n",
    "    'infer_max_step': 1024,\n",
    "    'output_dir': \"/home/qihao/CS6207/octuple/output\",\n",
    "}\n",
    "## tried t=1.6, topk=5, performed best for the PGPR workshop\n",
    "## tried t=1.3, topk=5, PB: 0.8790575894811564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9f197dd9-a209-46c7-96e8-664a52ed6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1234):  # seed setting\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # cuDNN在使用deterministic模式时（下面两行），可能会造成性能下降（取决于model）\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "5601fb7c-9c8f-4808-8180-c3ba34201b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, device):\n",
    "    model = Bart(event2word_dict=event2word_dict, \n",
    "                 word2event_dict=word2event_dict, \n",
    "                 model_pth='',\n",
    "                 hidden_size=hparams['hidden_size'], \n",
    "                 num_layers=hparams['n_layers'], \n",
    "                 num_heads=hparams['n_head'], \n",
    "                 dropout=hparams['drop_prob'],).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device), strict=True)\n",
    "    model.eval()\n",
    "    print(f\"| Successfully loaded bart ckpt from {checkpoint_path}.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "ab05e2b0-a7ec-4d65-96be-87178a053308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xe_loss(outputs, targets):\n",
    "    outputs = outputs.transpose(1, 2)\n",
    "    return F.cross_entropy(outputs, targets, ignore_index=0, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "a52c66ee-3f64-4cbe-a126-674ae7e7a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_data(data_sample, event2word_dict, word2event_dict):   \n",
    "    data = {}\n",
    "    for key, value in data_sample.items():\n",
    "        end_name, dict_key = key.split('_')\n",
    "        if dict_key.lower() == 'token':\n",
    "            dict_key = 'Pitch'\n",
    "        else:\n",
    "            dict_key = dict_key[0].upper() + dict_key[1:].lower()\n",
    "        input_tokens = []\n",
    "        for v in value:\n",
    "            # print(dict_key)\n",
    "            input_tokens.append(event2word_dict[dict_key][v])\n",
    "        data[key] = torch.LongTensor([copy.deepcopy(input_tokens)])\n",
    "\n",
    "    ## tgt_input:\n",
    "\n",
    "    '''\n",
    "    data = {\n",
    "        'src_strength': torch.LongTensor([[5, 3, 5, 3, 5, 3]]),\n",
    "        'src_length': torch.LongTensor([[3, 3, 4, 4, 4, 3]]),\n",
    "        'src_phrase': torch.LongTensor([[4, 4, 4, 4, 4, 3]]),\n",
    "        'tgt_bar': torch.LongTensor([[1, 3]]),\n",
    "        'tgt_pos': torch.LongTensor([[1, 75]]),\n",
    "        'tgt_token': torch.LongTensor([[1, 63]]),\n",
    "        'tgt_dur': torch.LongTensor([[1, 22]]),\n",
    "        'tgt_phrase': torch.LongTensor([[1, 4]]),\n",
    "    }\n",
    "    '''\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "47120fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_prosody(line):\n",
    "    length = len(line)\n",
    "    \n",
    "    # Predefined strength patterns for lengths 2 to 7\n",
    "    s_patterns = {\n",
    "        2: ['<strong>', '<weak>'],\n",
    "        3: ['<strong>', '<weak>', '<weak>'],\n",
    "        4: ['<strong>', '<weak>', '<strong>', '<weak>'],\n",
    "        5: ['<strong>', '<weak>', '<strong>', '<weak>', '<strong>'],\n",
    "        7: ['<strong>', '<weak>', '<strong>', '<weak>', '<weak>', '<weak>', '<strong>'],\n",
    "    }\n",
    "    \n",
    "    # Strength pattern generation for lengths 6 to 12\n",
    "    if length in s_patterns:\n",
    "        strength = s_patterns[length]\n",
    "    elif length % 2 == 0:\n",
    "        # Even length >= 6: alternate strong and weak, starting with strong\n",
    "        strength = ['<strong>' if i % 2 == 0 else '<weak>' for i in range(length)]\n",
    "    else:\n",
    "        # Odd length > 7: strong at 1st, 3rd, 7th positions (0-based), rest weak\n",
    "        strength = []\n",
    "        for i in range(length):\n",
    "            if i == 0 or i == 2 or i == 6:\n",
    "                strength.append('<strong>')\n",
    "            else:\n",
    "                strength.append('<weak>')\n",
    "    \n",
    "    # Length pattern: all <short> except last <long>\n",
    "    length_pattern = ['<short>'] * (length - 1) + ['<long>']\n",
    "    \n",
    "    # Phrase end pattern: all <false> except last <true>\n",
    "    phrase_end = ['<false>'] * (length - 1) + ['<true>']\n",
    "    \n",
    "    return strength, length_pattern, phrase_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9511adee-3e90-42a4-bdc2-7966185dffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosodic as p\n",
    "def convert_lyrics_to_input (lyrics, S, L, P):\n",
    "    # text = p.Text(lyrics)\n",
    "\n",
    "    s5 = ['<strong>', '<weak>', '<strong>', '<weak>', '<strong>']\n",
    "    l5 = ['<short>', '<short>', '<short>', '<short>', '<long>']\n",
    "    s7 = ['<strong>', '<weak>', '<strong>', '<weak>', '<weak>', '<weak>', '<strong>']\n",
    "    l7 = ['<short>', '<short>', '<short>', '<short>', '<short>', '<short>', '<long>']\n",
    "    p5 = ['<false>', '<false>', '<false>', '<false>', '<true>']\n",
    "    p7 = ['<false>', '<false>', '<false>', '<false>', '<false>', '<false>', '<true>']\n",
    "    \n",
    "    rep = 10\n",
    "    data_sample = {\n",
    "        # 'src_strength': ['<strong>', '<weak>', '<strong>', '<weak>', '<weak>', '<weak>', '<strong>']*rep*4,\n",
    "        # 'src_length': ['<short>', '<short>', '<short>', '<short>', '<short>', '<short>', '<long>']*rep*4,\n",
    "        # 'src_strength': s5*49+s7*72,\n",
    "        # 'src_length': l5*49+l7*72,\n",
    "        # 'src_phrase': p5*49+p7*72,\n",
    "        'src_strength': S,\n",
    "        'src_length': L,\n",
    "        'src_phrase': P,\n",
    "        'tgt_bar': [\"<s>\", \"Bar_0\"],\n",
    "        'tgt_pos': [\"<pad>\", \"Pos_0\"],\n",
    "        'tgt_token': [\"<pad>\", \"Pitch_60\"],\n",
    "        'tgt_dur': [\"<pad>\", \"Dur_120\"],\n",
    "        'tgt_phrase': [\"<pad>\", \"<false>\"],\n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    for line_id, line in enumerate(text.lines()):\n",
    "        words = line.words()\n",
    "        line_syllables = line.syllables()\n",
    "        line_syllable_num = len(line_syllables)\n",
    "\n",
    "        bound = '<false>'\n",
    "        \n",
    "        \n",
    "        ### src words\n",
    "        for syl_id, s in enumerate(line_syllables):\n",
    "            print(s, end='  ')\n",
    "            ## is accented:\n",
    "            if \"'\" in str(s): ## strong\n",
    "                mtype = \"<strong>\"\n",
    "            elif \"`\" in str(s):\n",
    "                mtype = \"<substrong>\"\n",
    "            else:\n",
    "                mtype = \"<weak>\"\n",
    "            length = \"<long>\" if \"ː\" in str(s) else \"<short>\"\n",
    "            # data_sample['src_strength'].append(mtype)\n",
    "            # data_sample['src_length'].append(length)\n",
    "            '''\n",
    "            if syl_id == len(line_syllables)-1:\n",
    "                data_sample['src_phrase'].append('<true>')\n",
    "            else:\n",
    "                data_sample['src_phrase'].append('<false>')\n",
    "            '''\n",
    "    \"\"\"\n",
    "\n",
    "    # data_sample['src_strength'] = data_sample['src_strength'] * 5\n",
    "    # data_sample['src_length'] = data_sample['src_length'] * 6\n",
    "    # data_sample['src_phrase'] = data_sample['src_phrase'] * rep\n",
    "    return data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "be3bfaa8-d010-4ad7-b880-b24def90520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_lyrics = '''Hey Jude don't make it bad\n",
    "Take a sad song and make it better\n",
    "Remember to let her into your heart\n",
    "Then you can start to make it better\n",
    "Hey Jude don't be afraid\n",
    "You were made to go out and get her\n",
    "The minute you let her under your skin\n",
    "Then you begin to make it better\n",
    "And anytime you feel the pain\n",
    "hey Jude refrain\n",
    "Don't carry the world upon your shoulders\n",
    "For well you know that it's a fool who plays it cool\n",
    "By making his world a little colder\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "86b780a0-a2b8-4ae8-b51d-d8d3bd5d391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_l2m(data_sample, output_dir='./', song_name='0'):\n",
    "    ## -------------------\n",
    "    ##     Bart Model\n",
    "    ## -------------------\n",
    "    set_seed()\n",
    "    print(f\"Using device: {device} for inferences custom samples\")\n",
    "    \n",
    "    # training conditions (for naming the ckpt)\n",
    "    lr = hparams['lr']\n",
    "    \n",
    "    ckpt_path = os.path.join(ckpt_dir, 'best.pt')\n",
    "\n",
    "    # load dictionary\n",
    "    event2word_dict, word2event_dict = pickle.load(open(f\"{binary_dir}/music_dict.pkl\", 'rb'))\n",
    "\n",
    "    # load melody generation model based on skeleton framework\n",
    "    model = Bart(event2word_dict=event2word_dict, \n",
    "                 word2event_dict=word2event_dict, \n",
    "                 model_pth='',\n",
    "                 hidden_size=hparams['hidden_size'], \n",
    "                 num_layers=hparams['n_layers'], \n",
    "                 num_heads=hparams['n_head'], \n",
    "                 dropout=hparams['drop_prob'],).to(device)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=True)\n",
    "    model.eval()\n",
    "    print(f\"| Successfully loaded bart ckpt from {ckpt_path}.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    # Inference file path\n",
    "    # -------------------------------------------------------------------------------------------\n",
    "    # exp_date = get_time()\n",
    "    # melody_output_dir = os.path.join(hparams['output_dir'], f'{song_name}')\n",
    "    # melody_output_dir = f'./{song_name}'\n",
    "    # melody_output_dir = os.path.join(output_dir, song_name)\n",
    "    melody_output_dir = output_dir\n",
    "    if not os.path.exists(melody_output_dir):\n",
    "        os.mkdir(melody_output_dir)\n",
    "\n",
    "\n",
    "    data = convert_to_data(data_sample, event2word_dict, word2event_dict)\n",
    "    print(data)\n",
    "    \n",
    "    try:\n",
    "        data_name = song_name\n",
    "\n",
    "        enc_inputs = {k: data[f'src_{k}'].to(device) for k in src_keys}\n",
    "        dec_inputs = {k: data[f'tgt_{k}'].to(device) for k in tgt_keys}\n",
    "        \n",
    "        print(enc_inputs['strength'].shape)\n",
    "\n",
    "        prompt_step = len(data_sample['tgt_bar'])\n",
    "\n",
    "        dec_inputs_selected = {\n",
    "            'bar': dec_inputs['bar'][:, :prompt_step],\n",
    "            'pos': dec_inputs['pos'][:, :prompt_step],\n",
    "            'token': dec_inputs['token'][:, :prompt_step],\n",
    "            'dur': dec_inputs['dur'][:, :prompt_step],\n",
    "            'phrase': dec_inputs['phrase'][:, :prompt_step],\n",
    "        }\n",
    "        print(enc_inputs)\n",
    "        print(dec_inputs_selected)\n",
    "\n",
    "        decode_length = enc_inputs['strength'].shape[-1]+2\n",
    "        max_sent_len = 1024  # 1024\n",
    "\n",
    "        print(f\"Expected decode length: {decode_length}\")\n",
    "        _ = model.infer(enc_inputs=enc_inputs, \n",
    "                        dec_inputs_gt=dec_inputs_selected, \n",
    "                        decode_length=decode_length-prompt_step,\n",
    "                        sentence_maxlen=max_sent_len, \n",
    "                        temperature=hparams['temperature'], \n",
    "                        topk=hparams['topk'], \n",
    "                        device=device, \n",
    "                        output_dir=melody_output_dir, \n",
    "                        midi_name=data_name)\n",
    "\n",
    "        # print(f\"Generating {data_idx+1}/{len(test_loader)}, Name: {data_name}\")\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-\\nBad Item: {data_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca57e4-ea82-46a9-93b3-85c50395b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1516\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/0.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 78.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/1.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/2.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 78.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/3.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/4.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/5.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 79.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/6.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 78.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/7.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 78.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/8.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/9.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 76.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/10.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 76.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/11.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 76.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/12.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 78.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/13.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/14.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/15.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/16.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 79.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/17.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 78.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/18.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/19.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1024 [00:00<00:12, 76.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 71\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/20.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:13, 75.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/21.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 79.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/22.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/23.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/24.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 76.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/25.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/26.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/27.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 78.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/28.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 75.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/29.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:13, 77.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:12, 76.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/30.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 79.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:13, 75.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/31.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/32.mid\n",
      "34 34 34\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 34])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 5, 3, 5, 3, 5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 3, 4, 4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 3, 4, 4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 36\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 57/1024 [00:00<00:10, 89.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 57\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/33.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/34.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 89.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/35.mid\n",
      "18 18 18\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 18])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 20\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1024 [00:00<00:11, 86.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 19\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/36.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/37.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/38.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 101/1024 [00:01<00:10, 89.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 101\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/39.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1024 [00:00<00:11, 88.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 32\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/40.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:11, 88.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/41.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1024 [00:00<00:10, 89.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 71\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/42.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1024 [00:00<00:10, 87.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 71\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/43.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/44.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1024 [00:00<00:11, 88.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 44\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/45.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/46.mid\n",
      "30 30 30\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 30])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 32\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1024 [00:00<00:11, 87.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 28\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/47.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 44/1024 [00:00<00:11, 88.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 44\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/48.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1024 [00:00<00:11, 86.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 19\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/49.mid\n",
      "30 30 30\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 30])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 32\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1024 [00:00<00:11, 87.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 28\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/50.mid\n",
      "29 29 29\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 29])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 31\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1024 [00:00<00:11, 87.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 28\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/51.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/52.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/53.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/54.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/55.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/56.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/57.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/58.mid\n",
      "27 27 27\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5,\n",
      "         5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 27])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5,\n",
      "         5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 29\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1024 [00:00<00:10, 89.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 71\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/59.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 32/1024 [00:00<00:11, 88.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 32\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/60.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/61.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/62.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/63.mid\n",
      "21 21 21\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 21])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 23\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1024 [00:00<00:10, 89.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 71\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/64.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/65.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/66.mid\n",
      "21 21 21\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 21])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 23\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/67.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 50/1024 [00:00<00:10, 88.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 50\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/68.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/69.mid\n",
      "25 25 25\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5,\n",
      "         3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 25])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5,\n",
      "         3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 27\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/70.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/71.mid\n",
      "21 21 21\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 21])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 23\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 95/1024 [00:01<00:10, 89.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 95\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/72.mid\n",
      "29 29 29\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 15/1024 [00:00<00:11, 85.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 29])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 31\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 15\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/73.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 5/1024 [00:00<00:13, 76.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/74.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 4/1024 [00:00<00:13, 73.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 4\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/75.mid\n",
      "25 25 25\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 6/1024 [00:00<00:12, 78.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 25])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 27\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 6\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/76.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/77.mid\n",
      "21 21 21\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 21])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 23\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 42/1024 [00:00<00:11, 88.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 42\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/78.mid\n",
      "15 15 15\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 15])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 17\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 86.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/79.mid\n",
      "30 30 30\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1024 [00:00<00:12, 80.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 30])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3,\n",
      "         5, 3, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 32\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 7\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/80.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/81.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 88.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/82.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/83.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 87.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/84.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 128/1024 [00:01<00:10, 89.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 128\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/85.mid\n",
      "23 23 23\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 23])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 25\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 88.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/86.mid\n",
      "10 10 10\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 3, 4, 3, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 3, 4, 3, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 10])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 3, 4, 3, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 3, 4, 3, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 12\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 88.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/87.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 92.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 95/1024 [00:01<00:10, 89.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 95\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/88.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1024 [00:00<00:12, 79.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 7\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/89.mid\n",
      "14 14 14\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 14])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 16\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/90.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 113/1024 [00:01<00:10, 89.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 113\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/91.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/92.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 5/1024 [00:00<00:13, 76.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/93.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 87.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/94.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/95.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/96.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 7/1024 [00:00<00:12, 80.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 7\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/97.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/98.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 42/1024 [00:00<00:11, 88.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 42\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/99.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 92.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1024 [00:00<00:11, 88.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 45\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/100.mid\n",
      "21 21 21\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1024 [00:00<00:12, 83.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 21])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 23\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 11\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/101.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/102.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/103.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1024 [00:00<00:12, 78.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 6\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/104.mid\n",
      "23 23 23\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 23])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 25\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1024 [00:00<00:11, 86.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 19\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/105.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 88.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/106.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/107.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/108.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/109.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/110.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/111.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/112.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/113.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/114.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/115.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/116.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/117.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/118.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/119.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/120.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/121.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/122.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:11, 88.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/123.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/124.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/125.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/126.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/127.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 80.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 8\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/128.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 90.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/129.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 75.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/130.mid\n",
      "25 25 25\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 8/1024 [00:00<00:12, 80.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 25])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 27\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 8\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/131.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 90.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/132.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/133.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/134.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/135.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/136.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/137.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/138.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/139.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/140.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/141.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/142.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/143.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/144.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/145.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/146.mid\n",
      "21 21 21\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 13/1024 [00:00<00:12, 83.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 21])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 23\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 13\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/147.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 90.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 128/1024 [00:01<00:10, 88.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 128\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/148.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/149.mid\n",
      "18 18 18\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 18])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 20\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 94/1024 [00:01<00:10, 88.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 94\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/150.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 128/1024 [00:01<00:10, 88.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 128\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/151.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1024 [00:00<00:13, 78.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 6\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/152.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 90.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 108/1024 [00:01<00:10, 87.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 108\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/153.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/154.mid\n",
      "30 30 30\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 30])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 32\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1024 [00:00<00:11, 86.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 28\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/155.mid\n",
      "33 33 33\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1024 [00:00<00:12, 79.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 33])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5,\n",
      "         3, 5, 3, 5, 3, 5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         4, 3, 4, 4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 35\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 7\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/156.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 90.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 87.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/157.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/158.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 120/1024 [00:01<00:10, 88.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 120\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/159.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/160.mid\n",
      "30 30 30\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 5, 5, 5, 5, 3,\n",
      "         5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 30])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 5, 5, 5, 5, 3,\n",
      "         5, 3, 5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 32\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 52/1024 [00:00<00:11, 88.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 52\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/161.mid\n",
      "18 18 18\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 18])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 20\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 101/1024 [00:01<00:10, 88.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 101\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/162.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/163.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 39/1024 [00:00<00:11, 87.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 39\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/164.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/165.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/166.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/167.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/168.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/169.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/170.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/171.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/172.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/173.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/174.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/175.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/176.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/177.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/178.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/179.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/180.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/181.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/182.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 84.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/183.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 88.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/184.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/185.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/186.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/187.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/188.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1024 [00:00<00:11, 89.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/189.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/190.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/191.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/192.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/193.mid\n",
      "23 23 23\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 23])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 25\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 87.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/194.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1024 [00:00<00:10, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 71\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/195.mid\n",
      "23 23 23\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 23])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 25\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/196.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/197.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/198.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/199.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/200.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/201.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/202.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 88.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/203.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 88.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/204.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/205.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 90.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 87/1024 [00:00<00:10, 87.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 87\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/206.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/207.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 114/1024 [00:01<00:10, 88.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 114\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/208.mid\n",
      "21 21 21\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 21])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 23\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 102/1024 [00:01<00:10, 89.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 102\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/209.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 88.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/210.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/211.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/212.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/213.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/214.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/215.mid\n",
      "18 18 18\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 18])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 20\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 101/1024 [00:01<00:10, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 101\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/216.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/217.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/218.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/219.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 88.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/220.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/221.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/222.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/223.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 81.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 8\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/224.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 95/1024 [00:01<00:10, 89.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 95\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/225.mid\n",
      "8 8 8\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 3, 5, 5, 3, 5, 3, 5]]), 'src_length': tensor([[3, 4, 4, 3, 4, 3, 4, 3]]), 'src_phrase': tensor([[3, 4, 4, 3, 4, 3, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 8])\n",
      "{'strength': tensor([[3, 3, 5, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[3, 4, 4, 3, 4, 3, 4, 3]], device='cuda:1'), 'phrase': tensor([[3, 4, 4, 3, 4, 3, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 10\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 169/1024 [00:01<00:09, 88.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 169\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/226.mid\n",
      "14 14 14\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 14])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 16\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 88.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/227.mid\n",
      "14 14 14\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 14])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3]], device='cuda:1'), 'length': tensor([[4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 16\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 107/1024 [00:01<00:10, 88.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 107\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/228.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/229.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/230.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/231.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/232.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/233.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/234.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 88.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/235.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/236.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/237.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/238.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/239.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/240.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1024 [00:00<00:12, 80.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 7\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/241.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/242.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/243.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/244.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 101/1024 [00:01<00:10, 89.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 101\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/245.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/246.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1024 [00:00<00:11, 87.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:12, 82.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/247.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/248.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 38/1024 [00:00<00:11, 88.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 38\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/249.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/250.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 88.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/251.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 87.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/252.mid\n",
      "30 30 30\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 30])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 32\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 28/1024 [00:00<00:11, 87.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 28\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/253.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/254.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/255.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/256.mid\n",
      "25 25 25\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1024 [00:00<00:12, 83.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3,\n",
      "         5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 25])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3,\n",
      "         5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4,\n",
      "         3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 27\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 11\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/257.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 15/1024 [00:00<00:11, 85.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5,\n",
      "         3, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5,\n",
      "         3, 3, 5, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 15\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/258.mid\n",
      "18 18 18\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 18])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 20\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1024 [00:00<00:11, 86.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 19\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/259.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 88.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/260.mid\n",
      "17 17 17\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 17])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 19\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/261.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/262.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/263.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 85.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/264.mid\n",
      "25 25 25\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/1024 [00:00<00:12, 81.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 25])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 27\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 8\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/265.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 7/1024 [00:00<00:12, 80.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 7\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/266.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 62/1024 [00:00<00:10, 89.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 62\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/267.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/268.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/269.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/270.mid\n",
      "27 27 27\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 27])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 29\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/271.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 128/1024 [00:01<00:10, 89.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 128\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/272.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 88.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/273.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/274.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/275.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 58/1024 [00:00<00:10, 89.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 58\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/276.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 95/1024 [00:01<00:10, 89.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 95\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/277.mid\n",
      "27 27 27\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5,\n",
      "         5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 27])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5,\n",
      "         5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4,\n",
      "         4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 29\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 50/1024 [00:00<00:10, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 50\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/278.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/279.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/280.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 86.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/281.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/282.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/283.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/284.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/285.mid\n",
      "25 25 25\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 25])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 27\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 18/1024 [00:00<00:11, 85.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 18\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/286.mid\n",
      "16 16 16\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 16])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 18\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1024 [00:00<00:11, 86.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 20\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/287.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 89.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/288.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 5, 3, 5, 3, 5, 3, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 21/1024 [00:00<00:11, 87.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 21\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/289.mid\n",
      "19 19 19\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1024 [00:00<00:13, 76.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 19])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 21\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 5\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/290.mid\n",
      "25 25 25\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 8/1024 [00:00<00:12, 81.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3]]), 'src_length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'src_phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 25])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5,\n",
      "         3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4,\n",
      "         3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 27\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 8\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/291.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/292.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/293.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/294.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/295.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/296.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/297.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/298.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1024 [00:00<00:11, 88.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 41\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/299.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 88.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/300.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 88.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/301.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/302.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/303.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/304.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/305.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/306.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 63/1024 [00:00<00:10, 89.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 63\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/307.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/308.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 88.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/309.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/310.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1024 [00:00<00:11, 88.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:11, 85.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/311.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/1024 [00:00<00:11, 89.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/312.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/313.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1024 [00:00<00:11, 88.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 41\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/314.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/315.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 88.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/316.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1024 [00:00<00:11, 88.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 41\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/317.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 88.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/318.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/319.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/320.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/321.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/322.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/323.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/324.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/325.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 5]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 88.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/326.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/1024 [00:00<00:12, 79.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n",
      "Decode ends at step 7\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/327.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1024 [00:00<00:11, 91.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/328.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/329.mid\n",
      "24 24 24\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 24])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 26\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 71/1024 [00:00<00:10, 89.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 71\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/330.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/331.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/332.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/333.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:11, 86.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/334.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/335.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/336.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/337.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/338.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:11, 87.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/339.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/340.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 86.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/341.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/342.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/343.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/344.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/345.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/346.mid\n",
      "14 14 14\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5]]), 'src_length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 14])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 3, 5, 3, 5]], device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 16\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 169/1024 [00:01<00:09, 88.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 169\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/347.mid\n",
      "18 18 18\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 18])\n",
      "{'strength': tensor([[3, 5, 5, 3, 5, 5, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 20\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 94/1024 [00:01<00:10, 89.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 94\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/348.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/349.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/350.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/351.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/352.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 87.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/353.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/354.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:11, 88.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/355.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 63/1024 [00:00<00:10, 88.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 63\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/356.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 87.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/357.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 63/1024 [00:00<00:10, 88.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 63\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/358.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 87.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/359.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/360.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 63/1024 [00:00<00:10, 89.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 63\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/361.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/362.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/363.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1024 [00:00<00:11, 88.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 33\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/364.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 88.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/365.mid\n",
      "28 28 28\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 28])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3,\n",
      "         5, 5, 5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n",
      "         4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 30\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 55/1024 [00:00<00:10, 89.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 55\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/366.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 123/1024 [00:01<00:10, 89.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 123\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/367.mid\n",
      "12 12 12\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 90.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 12])\n",
      "{'strength': tensor([[3, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]], device='cuda:1'), 'length': tensor([[3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1'), 'phrase': tensor([[3, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 14\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 106/1024 [00:01<00:10, 88.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 106\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/368.mid\n",
      "26 26 26\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 26])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 5,\n",
      "         5, 3]], device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4,\n",
      "         4, 3]], device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 28\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 35/1024 [00:00<00:11, 88.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 35\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/369.mid\n",
      "22 22 22\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 22])\n",
      "{'strength': tensor([[3, 5, 3, 5, 5, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 24\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 41/1024 [00:00<00:11, 88.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 41\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/370.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/371.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/372.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/373.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/374.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/375.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/376.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 88.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/377.mid\n",
      "20 20 20\n",
      "Using device: cuda:1 for inferences custom samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1024 [00:00<00:11, 91.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Successfully loaded bart ckpt from /data1/qihao/cs6207/octuple/checkpoints/checkpoint_20240406:190014_lr_5e-05/best.pt.\n",
      "{'src_strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]]), 'src_length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'src_phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]]), 'tgt_bar': tensor([[0, 3]]), 'tgt_pos': tensor([[1, 3]]), 'tgt_token': tensor([[ 1, 63]]), 'tgt_dur': tensor([[1, 8]]), 'tgt_phrase': tensor([[1, 4]])}\n",
      "torch.Size([1, 20])\n",
      "{'strength': tensor([[3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 5, 3, 5, 3]],\n",
      "       device='cuda:1'), 'length': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1'), 'phrase': tensor([[4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3]],\n",
      "       device='cuda:1')}\n",
      "{'bar': tensor([[0, 3]], device='cuda:1'), 'pos': tensor([[1, 3]], device='cuda:1'), 'token': tensor([[ 1, 63]], device='cuda:1'), 'dur': tensor([[1, 8]], device='cuda:1'), 'phrase': tensor([[1, 4]], device='cuda:1')}\n",
      "Expected decode length: 22\n",
      "Sampling strategy: temperature-1.6, top-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1024 [00:00<00:11, 87.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode ends at step 26\n",
      "/home/qihao/MelodyBot/3_inference/Output/workshop/378.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = '/home/qihao/muzic/telemelody/inference/results/poems_dataset.txt'\n",
    "with open(dataset, 'r') as ds:\n",
    "    all_lines = ds.read().split()\n",
    "print(len(all_lines))\n",
    "ds.close()\n",
    "\n",
    "song_id = 0\n",
    "step = 90\n",
    "for ts in range(0, len(all_lines), step):\n",
    "    S, L, P = [], [], []\n",
    "    if ts + step <= len(all_lines):\n",
    "        for idx in range(ts, ts+step):\n",
    "            line = all_lines[idx]\n",
    "            s, l, p = line_to_prosody(line)\n",
    "            S.extend(s.copy())\n",
    "            L.extend(l.copy())\n",
    "            P.extend(p.copy())\n",
    "    else:\n",
    "        for idx in range(ts, len(all_lines)):\n",
    "            line = all_lines[idx]\n",
    "            s, l, p = line_to_prosody(line)\n",
    "            S.extend(s.copy())\n",
    "            L.extend(l.copy())\n",
    "            P.extend(p.copy())\n",
    "    print(len(S), len(L), len(P))\n",
    "    sample = convert_lyrics_to_input(char_lyrics, S.copy(), L.copy(), P.copy())\n",
    "    infer_l2m(sample, output_dir='/home/qihao/MelodyBot/3_inference/Output/workshop', song_name=str(song_id))\n",
    "    song_id = song_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "7c059b92-56bf-48be-b29d-fbb300da6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate (lyrics_in):\n",
    "    test_sample = convert_lyrics_to_input(lyrics_in)\n",
    "    infer_l2m(sample, output_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "be4fffd2-0143-41cd-b060-5d3fc83ef9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xailyr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
