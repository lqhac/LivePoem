{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bfc3088-89be-4083-989d-3cbc3a471847",
   "metadata": {},
   "source": [
    "### Infer single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54616499-4aa6-4106-b05f-5b2f8e508329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_path = './'  ## replace this with your root path (i.e., path of this current project)\n",
    "os.environ['PYTHONPATH'] = root_path\n",
    "sys.path.append(root_path)\n",
    "import pickle\n",
    "import traceback\n",
    "import random\n",
    "import subprocess\n",
    "import torch.cuda\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.earlystopping.protocols import EarlyStopping\n",
    "from utils.test_dataloder import *\n",
    "import datetime\n",
    "from utils.get_time import get_time\n",
    "import gc, copy\n",
    "from tqdm import tqdm\n",
    "from utils.warmup import *\n",
    "import torch.nn.functional as F\n",
    "from models.bartmodel_octuple import Bart\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import prosodic as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e696daa-1c57-4b35-8aad-3c65bde8fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52e9a3-3226-4ca6-982b-c357a3e23789",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_name = ''  ## replace with your checkpoint name\n",
    "ckpt_dir = f'./checkpoints/{ckpt_name}' ## replace with your checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90aa88-dabb-44e9-8df1-6215d474e968",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_keys = ['strength', 'length', 'phrase']\n",
    "tgt_keys = ['bar', 'pos', 'token', 'dur', 'phrase']\n",
    "\n",
    "\n",
    "binary_dir = './binary' ## replace with your path to dictionaries\n",
    "words_dir = './binary/words' ## replace with your path to binary words\n",
    "hparams = {\n",
    "    'batch_size': 1,\n",
    "    'word_data_dir': words_dir,\n",
    "    'sentence_maxlen': 512,\n",
    "    'hidden_size': 768,\n",
    "    'n_layers': 6,\n",
    "    'n_head': 8,\n",
    "    'pretrain': '',\n",
    "    'lr': 5.0e-5,\n",
    "    'optimizer_adam_beta1': 0.9,\n",
    "    'optimizer_adam_beta2': 0.98,\n",
    "    'weight_decay': 0.001,\n",
    "    'patience': 5,\n",
    "    'warmup': 2500,\n",
    "    'lr': 5.0e-5,\n",
    "    'checkpoint_dir': './checkpoints', ## replace with your checkpoint directory\n",
    "    'drop_prob': 0.2,\n",
    "    'total_epoch': 1000,\n",
    "    'infer_batch_size': 1,\n",
    "    'temperature': 1.6,\n",
    "    'topk': 5,\n",
    "    'prompt_step': 1,\n",
    "    'infer_max_step': 1024,\n",
    "    'output_dir': \"/home/qihao/CS6207/octuple/output\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f197dd9-a209-46c7-96e8-664a52ed6176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1234):  # seed setting\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601fb7c-9c8f-4808-8180-c3ba34201b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, device):\n",
    "    model = Bart(event2word_dict=event2word_dict, \n",
    "                 word2event_dict=word2event_dict, \n",
    "                 model_pth='',\n",
    "                 hidden_size=hparams['hidden_size'], \n",
    "                 num_layers=hparams['n_layers'], \n",
    "                 num_heads=hparams['n_head'], \n",
    "                 dropout=hparams['drop_prob'],).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device), strict=True)\n",
    "    model.eval()\n",
    "    print(f\"| Successfully loaded bart ckpt from {checkpoint_path}.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05e2b0-a7ec-4d65-96be-87178a053308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xe_loss(outputs, targets):\n",
    "    outputs = outputs.transpose(1, 2)\n",
    "    return F.cross_entropy(outputs, targets, ignore_index=0, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c66ee-3f64-4cbe-a126-674ae7e7a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_data(data_sample, event2word_dict, word2event_dict):   \n",
    "    data = {}\n",
    "    for key, value in data_sample.items():\n",
    "        end_name, dict_key = key.split('_')\n",
    "        if dict_key.lower() == 'token':\n",
    "            dict_key = 'Pitch'\n",
    "        else:\n",
    "            dict_key = dict_key[0].upper() + dict_key[1:].lower()\n",
    "        input_tokens = []\n",
    "        for v in value:\n",
    "            # print(dict_key)\n",
    "            input_tokens.append(event2word_dict[dict_key][v])\n",
    "        data[key] = torch.LongTensor([copy.deepcopy(input_tokens)])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47120fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_prosody(line):\n",
    "    length = len(line)\n",
    "    \n",
    "    # Predefined strength patterns for lengths 2 to 7\n",
    "    s_patterns = {\n",
    "        2: ['<strong>', '<weak>'],\n",
    "        3: ['<strong>', '<weak>', '<weak>'],\n",
    "        4: ['<strong>', '<weak>', '<strong>', '<weak>'],\n",
    "        5: ['<strong>', '<weak>', '<strong>', '<weak>', '<strong>'],\n",
    "        7: ['<strong>', '<weak>', '<strong>', '<weak>', '<weak>', '<weak>', '<strong>'],\n",
    "    }\n",
    "    \n",
    "    # Strength pattern generation for lengths 6 to 12\n",
    "    if length in s_patterns:\n",
    "        strength = s_patterns[length]\n",
    "    elif length % 2 == 0:\n",
    "        # Even length >= 6: alternate strong and weak, starting with strong\n",
    "        strength = ['<strong>' if i % 2 == 0 else '<weak>' for i in range(length)]\n",
    "    else:\n",
    "        # Odd length > 7: strong at 1st, 3rd, 7th positions (0-based), rest weak\n",
    "        strength = []\n",
    "        for i in range(length):\n",
    "            if i == 0 or i == 2 or i == 6:\n",
    "                strength.append('<strong>')\n",
    "            else:\n",
    "                strength.append('<weak>')\n",
    "    \n",
    "    # Length pattern: all <short> except last <long>\n",
    "    length_pattern = ['<short>'] * (length - 1) + ['<long>']\n",
    "    \n",
    "    # Phrase end pattern: all <false> except last <true>\n",
    "    phrase_end = ['<false>'] * (length - 1) + ['<true>']\n",
    "    \n",
    "    return strength, length_pattern, phrase_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511adee-3e90-42a4-bdc2-7966185dffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prosodic as p\n",
    "def convert_lyrics_to_input (lyrics, S, L, P):\n",
    "    \n",
    "    rep = 10\n",
    "    data_sample = {\n",
    "        'src_strength': S,\n",
    "        'src_length': L,\n",
    "        'src_phrase': P,\n",
    "        'tgt_bar': [\"<s>\", \"Bar_0\"],\n",
    "        'tgt_pos': [\"<pad>\", \"Pos_0\"],\n",
    "        'tgt_token': [\"<pad>\", \"Pitch_60\"],\n",
    "        'tgt_dur': [\"<pad>\", \"Dur_120\"],\n",
    "        'tgt_phrase': [\"<pad>\", \"<false>\"],\n",
    "    }\n",
    "    \n",
    "\n",
    "    return data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b780a0-a2b8-4ae8-b51d-d8d3bd5d391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_l2m(data_sample, output_dir='./', song_name='0'):\n",
    "    ##     Bart Model\n",
    "    set_seed()\n",
    "    print(f\"Using device: {device} for inferences custom samples\")\n",
    "    \n",
    "    # training conditions (for naming the ckpt)\n",
    "    lr = hparams['lr']\n",
    "    \n",
    "    ckpt_path = os.path.join(ckpt_dir, 'best.pt')\n",
    "\n",
    "    # load dictionary\n",
    "    event2word_dict, word2event_dict = pickle.load(open(f\"{binary_dir}/music_dict.pkl\", 'rb'))\n",
    "\n",
    "    # load melody generation model based on skeleton framework\n",
    "    model = Bart(event2word_dict=event2word_dict, \n",
    "                 word2event_dict=word2event_dict, \n",
    "                 model_pth='',\n",
    "                 hidden_size=hparams['hidden_size'], \n",
    "                 num_layers=hparams['n_layers'], \n",
    "                 num_heads=hparams['n_head'], \n",
    "                 dropout=hparams['drop_prob'],).to(device)\n",
    "    model.load_state_dict(torch.load(ckpt_path, map_location=device), strict=True)\n",
    "    model.eval()\n",
    "    print(f\"| Successfully loaded bart ckpt from {ckpt_path}.\")\n",
    "\n",
    "    # Inference file path\n",
    "    melody_output_dir = output_dir\n",
    "    if not os.path.exists(melody_output_dir):\n",
    "        os.mkdir(melody_output_dir)\n",
    "\n",
    "\n",
    "    data = convert_to_data(data_sample, event2word_dict, word2event_dict)\n",
    "    print(data)\n",
    "    \n",
    "    try:\n",
    "        data_name = song_name\n",
    "\n",
    "        enc_inputs = {k: data[f'src_{k}'].to(device) for k in src_keys}\n",
    "        dec_inputs = {k: data[f'tgt_{k}'].to(device) for k in tgt_keys}\n",
    "        \n",
    "        print(enc_inputs['strength'].shape)\n",
    "\n",
    "        prompt_step = len(data_sample['tgt_bar'])\n",
    "\n",
    "        dec_inputs_selected = {\n",
    "            'bar': dec_inputs['bar'][:, :prompt_step],\n",
    "            'pos': dec_inputs['pos'][:, :prompt_step],\n",
    "            'token': dec_inputs['token'][:, :prompt_step],\n",
    "            'dur': dec_inputs['dur'][:, :prompt_step],\n",
    "            'phrase': dec_inputs['phrase'][:, :prompt_step],\n",
    "        }\n",
    "        print(enc_inputs)\n",
    "        print(dec_inputs_selected)\n",
    "\n",
    "        decode_length = enc_inputs['strength'].shape[-1]+2\n",
    "        max_sent_len = 1024  # 1024\n",
    "\n",
    "        print(f\"Expected decode length: {decode_length}\")\n",
    "        _ = model.infer(enc_inputs=enc_inputs, \n",
    "                        dec_inputs_gt=dec_inputs_selected, \n",
    "                        decode_length=decode_length-prompt_step,\n",
    "                        sentence_maxlen=max_sent_len, \n",
    "                        temperature=hparams['temperature'], \n",
    "                        topk=hparams['topk'], \n",
    "                        device=device, \n",
    "                        output_dir=melody_output_dir, \n",
    "                        midi_name=data_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        print(f\"-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-!-\\nBad Item: {data_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca57e4-ea82-46a9-93b3-85c50395b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = './poems_dataset.txt' ## path to a poem dataset\n",
    "with open(dataset, 'r') as ds:\n",
    "    all_lines = ds.read().split()\n",
    "print(len(all_lines))\n",
    "ds.close()\n",
    "\n",
    "song_id = 0\n",
    "step = 90\n",
    "for ts in range(0, len(all_lines), step):\n",
    "    S, L, P = [], [], []\n",
    "    if ts + step <= len(all_lines):\n",
    "        for idx in range(ts, ts+step):\n",
    "            line = all_lines[idx]\n",
    "            s, l, p = line_to_prosody(line)\n",
    "            S.extend(s.copy())\n",
    "            L.extend(l.copy())\n",
    "            P.extend(p.copy())\n",
    "    else:\n",
    "        for idx in range(ts, len(all_lines)):\n",
    "            line = all_lines[idx]\n",
    "            s, l, p = line_to_prosody(line)\n",
    "            S.extend(s.copy())\n",
    "            L.extend(l.copy())\n",
    "            P.extend(p.copy())\n",
    "    print(len(S), len(L), len(P))\n",
    "    sample = convert_lyrics_to_input(char_lyrics, S.copy(), L.copy(), P.copy())\n",
    "    infer_l2m(sample, output_dir='/home/qihao/MelodyBot/3_inference/Output/workshop', song_name=str(song_id))\n",
    "    song_id = song_id + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xailyr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
