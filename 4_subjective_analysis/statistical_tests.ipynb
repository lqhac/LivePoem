{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59c6a74",
   "metadata": {},
   "source": [
    "#### **Codes for the Statistical Analyses in the User Study of LivePoem**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720a920f",
   "metadata": {},
   "source": [
    "##### Step1: Import Libraries and Result File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5cb41",
   "metadata": {},
   "source": [
    "*N.B. To protect the privacy of participants, we **anonymised** the result file by filtering the personal information in the first several columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d221da-c8b1-4951-8912-73aac9d83b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp, mannwhitneyu\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f795df13-9cad-429e-9b37-b7750ad0b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and read the results file\n",
    "table_path = f\"./test_results.csv\"\n",
    "df = pd.read_csv(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87559f1-f3ff-4e58-ab4e-5ad0eb6953fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## question ids\n",
    "before_ids = [5, 10, 15, 20, 25]  ## The question IDs for pre-tests\n",
    "after_ids_txt = [4, 10, 16, 22, 28] ## The question IDs for post-tests under textbook condition (TB)\n",
    "after_ids_vis = [3, 8, 13, 18, 23] ## The question IDs for post-tests under storyboard condition (SB)\n",
    "\n",
    "## block ids\n",
    "before_blks_txt = [7, 13]  ## The question block IDs for pre-test samples under textbook condition (TB)\n",
    "before_blks_vis = [9, 11]  ## The question block IDs for pre-test samples under storyboard condition (SB)\n",
    "before_blks = before_blks_vis + before_blks_txt  ## All the pre-test samples\n",
    "\n",
    "rating_txt = [\"16.2\", \"16.3\", \"16.4\"]  ## The question IDs for SAM ratings under textbook condition (TB)\n",
    "rating_vis = [\"15.2\", \"15.3\", \"15.4\"]  ## The question IDs for SAM ratings under storyboard condition (SB)\n",
    "\n",
    "### The IDs for correct answers for each question\n",
    "### The dictionary if formatted as:\n",
    "### Each item is \"the ID of the poetry: correct answers for the five questions\"\n",
    "answer_ids = {\n",
    "    7: [1, 1, 4, 2, 3],\n",
    "    9: [1, 4, 3, 2, 1],\n",
    "    11: [2, 3, 1, 1, 4],\n",
    "    13: [1, 2, 2, 4, 4],\n",
    "    8: [1, 1, 4, 2, 3],\n",
    "    10: [1, 4, 3, 2, 1],\n",
    "    12: [2, 3, 1, 1, 4],\n",
    "    14: [1, 2, 2, 4, 4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1277104-9190-4e53-ac86-821646cc974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender: {'1': 14, '2': 10, '3': 0, '4': 1}\n",
      "Language Proficiency: {'1': 1, '2': 14, '3': 10, '4': 0, '5': 0}\n",
      "Music Proficiency: {'1': 16, '2': 8, '3': 1}\n"
     ]
    }
   ],
   "source": [
    "## demographic information\n",
    "## telephone number is Q2.4\n",
    "## gender Q2.5 1-male; 2-female; 3-non-binary/third; 4-prefer not to say\n",
    "## Chinese proficiency Q2.6 1-5\n",
    "## Music proficiency Q2.7\n",
    "\n",
    "## Initialise several dictionaries for counting the demographic information\n",
    "gender = {\n",
    "    '1': 0,  ## Male\n",
    "    '2': 0,  ## Female\n",
    "    '3': 0,  ## Non-binary\n",
    "    '4': 0,  ## Prefer not to disclose\n",
    "}\n",
    "lang_prof = {  ## ILR Scale\n",
    "    '1': 0,\n",
    "    '2': 0,\n",
    "    '3': 0,\n",
    "    '4': 0,\n",
    "    '5': 0\n",
    "}\n",
    "music_prof = {\n",
    "    '1': 0,  ## Beginner\n",
    "    '2': 0,  ## Intermediate\n",
    "    '3': 0,  ## Advanced\n",
    "}\n",
    "users = {}  ## User ID (for data aggregation)\n",
    "parti_nbr = 0  ## Count the number of participants (i.e., the valid responses)\n",
    "\n",
    "## Structure the data\n",
    "for idx, row in df.iterrows(): \n",
    "    if row['Finished'] == 0:  ## Filter unfinished questionnaires\n",
    "        continue\n",
    "    ## Retrieve the information\n",
    "    user_id = str(int(row['Q2.4'])).strip()\n",
    "    if user_id not in users.keys():\n",
    "        users[user_id] = []\n",
    "    user_gender = str(int(row['Q2.5']))\n",
    "    gender[user_gender] += 1\n",
    "    user_language = str(int(row['Q2.6']))\n",
    "    lang_prof[user_language] += 1\n",
    "    user_music = str(int(row['Q2.7']))\n",
    "    music_prof[user_music] += 1\n",
    "    users[user_id].extend([user_gender, user_language, user_music])\n",
    "    parti_nbr += 1\n",
    "\n",
    "## Print the demographic information\n",
    "print(f\"Gender: {gender}\\nLanguage Proficiency: {lang_prof}\\nMusic Proficiency: {music_prof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f447a397",
   "metadata": {},
   "source": [
    "##### Step2: Computing Test Performance in Pre- and Post-Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385452f7-1bd4-45a1-bfd1-d1ce9a29a9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance in pre-test (SB condition)\n",
      "Mean: 0.6519999999999999\n",
      "SD: 0.20023985617254125\n"
     ]
    }
   ],
   "source": [
    "## Test performance in pre-test (SB condition)\n",
    "## collect participants accuracy before viewing STORYBOARDS\n",
    "accuracy_before_vis_user = {}\n",
    "true_cnt, total_cnt = 0, 0\n",
    "for idx, row in df.iterrows():\n",
    "    if row['Finished'] == 0:\n",
    "        continue\n",
    "    user_id = str(int(row['Q2.4'])).strip()\n",
    "    if user_id not in accuracy_before_vis_user.keys():\n",
    "        accuracy_before_vis_user[user_id] = 0\n",
    "    if len(users[user_id]) <= 3:\n",
    "        users[user_id].append({})\n",
    "    for b_blk_id in before_blks_vis:\n",
    "        sample_id = f\"{b_blk_id}_SB_Bef\"\n",
    "        if sample_id not in users[user_id][3].keys():\n",
    "            users[user_id][3][sample_id] = []\n",
    "        for ques_idx, b_ques_id in enumerate(before_ids):\n",
    "            ans = int(row[f'Q{b_blk_id}.{b_ques_id}'])\n",
    "            gt = answer_ids[b_blk_id][ques_idx]\n",
    "            if ans == gt:\n",
    "                users[user_id][3][sample_id].append(1)\n",
    "                true_cnt += 1\n",
    "                accuracy_before_vis_user[user_id] += 1\n",
    "            else:\n",
    "                users[user_id][3][sample_id].append(0)\n",
    "            total_cnt += 1\n",
    "print(\"Test performance in pre-test (SB condition)\")\n",
    "accuracy_before_vis_user_list = np.array(list(accuracy_before_vis_user.values()))/10\n",
    "print(f\"Mean: {np.mean(accuracy_before_vis_user_list)}\\nSD: {np.std(accuracy_before_vis_user_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc51381-969b-4603-bfde-4e1ad4926b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance in post-test (SB condition)\n",
      "Mean: 0.7560000000000001\n",
      "SD: 0.12354756169184403\n"
     ]
    }
   ],
   "source": [
    "## Test performance in post-test (SB condition)\n",
    "## collect participants accuracy post viewing STORYBOARDS\n",
    "accuracy_after_vis_user = {}\n",
    "true_cnt, total_cnt = 0, 0\n",
    "for idx, row in df.iterrows():\n",
    "    if row['Finished'] == 0:\n",
    "        continue\n",
    "    user_id = str(int(row['Q2.4'])).strip()\n",
    "    if user_id not in accuracy_after_vis_user.keys():\n",
    "        accuracy_after_vis_user[user_id] = 0\n",
    "    if len(users[user_id]) <= 3:\n",
    "        users[user_id].append({})\n",
    "    for b_blk_id in before_blks_vis:\n",
    "        sample_id = f\"{b_blk_id}_SB_Aft\"\n",
    "        if sample_id not in users[user_id][3].keys():\n",
    "            users[user_id][3][sample_id] = []\n",
    "        for ques_idx, a_ques_id in enumerate(after_ids_vis):\n",
    "            ans = int(row[f'Q{b_blk_id+1}.{a_ques_id}'])\n",
    "            gt = answer_ids[b_blk_id+1][ques_idx]\n",
    "            if ans == gt:\n",
    "                users[user_id][3][sample_id].append(1)\n",
    "                true_cnt += 1\n",
    "                accuracy_after_vis_user[user_id] += 1\n",
    "            else:\n",
    "                users[user_id][3][sample_id].append(0)\n",
    "            total_cnt += 1\n",
    "print(f\"Test performance in post-test (SB condition)\")\n",
    "accuracy_after_vis_user_list = np.array(list(accuracy_after_vis_user.values()))/10\n",
    "print(f\"Mean: {np.mean(accuracy_after_vis_user_list)}\\nSD: {np.std(accuracy_after_vis_user_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36aeb22c-6985-4eca-aeb5-5248eb4c1ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical test results (SB condition)\n",
      "Shapiro-Wilk Test statistic: 0.9139395379488897, p-value: 0.03735121659857334\n",
      "Paired t-Test statistic: 3.2105290566166693, p-value: 0.0037439828228677838\n",
      "Wilcoxon signed-rank test statistic: 52.0, p-value: 0.014920784493116672\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "print(\"Statistical test results (SB condition)\")\n",
    "# Example data\n",
    "accuracy_before = np.array(accuracy_before_vis_user_list)  # Replace with your accuracy data before the test\n",
    "accuracy_after = np.array(accuracy_after_vis_user_list)   # Replace with your accuracy data after the test\n",
    "\n",
    "# Check normality of differences\n",
    "differences = accuracy_after - accuracy_before\n",
    "stat, p_value = stats.shapiro(differences)\n",
    "print(f'Shapiro-Wilk Test statistic: {stat}, p-value: {p_value}')\n",
    "\n",
    "# Perform Paired t-Test\n",
    "t_stat, p_value = stats.ttest_rel(accuracy_after, accuracy_before)\n",
    "print(f'Paired t-Test statistic: {t_stat}, p-value: {p_value}')\n",
    "\n",
    "# Perform Wilcoxon signed-rank test\n",
    "# stat, p_value = stats.wilcoxon(accuracy_after - accuracy_before)\n",
    "stat, p_value = stats.wilcoxon(accuracy_after_vis_user_list - accuracy_before_vis_user_list)\n",
    "print(f'Wilcoxon signed-rank test statistic: {stat}, p-value: {p_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b86a25d-0c5b-464c-b875-149d83185e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance in pre-test (TB condition)\n",
      "Mean: 0.6\n",
      "SD: 0.2513961017995307\n"
     ]
    }
   ],
   "source": [
    "## Test performance in pre-test (TB condition)\n",
    "## collect participants accuracy before viewing TEXTBOOKS\n",
    "true_cnt, total_cnt = 0, 0\n",
    "accuracy_before_txt_user = {}\n",
    "for idx, row in df.iterrows():\n",
    "    if row['Finished'] == 0:\n",
    "        continue\n",
    "    user_id = str(int(row['Q2.4'])).strip()\n",
    "    if user_id not in accuracy_before_txt_user.keys():\n",
    "        accuracy_before_txt_user[user_id] = 0\n",
    "    if len(users[user_id]) <= 3:\n",
    "        users[user_id].append({})\n",
    "    for b_blk_id in before_blks_txt:\n",
    "        sample_id = f\"{b_blk_id}_TB_Bef\"\n",
    "        if sample_id not in users[user_id][3].keys():\n",
    "            users[user_id][3][sample_id] = []\n",
    "        for ques_idx, b_ques_id in enumerate(before_ids):\n",
    "            ans = int(row[f'Q{b_blk_id}.{b_ques_id}'])\n",
    "            gt = answer_ids[b_blk_id][ques_idx]\n",
    "            if ans == gt:\n",
    "                users[user_id][3][sample_id].append(1)\n",
    "                accuracy_before_txt_user[user_id] += 1\n",
    "                true_cnt += 1\n",
    "            else:\n",
    "                users[user_id][3][sample_id].append(0)\n",
    "            total_cnt += 1\n",
    "\n",
    "print(f\"Test performance in pre-test (TB condition)\")\n",
    "accuracy_before_txt_user_list = np.array(list(accuracy_before_txt_user.values()))/10\n",
    "print(f\"Mean: {np.mean(accuracy_before_txt_user_list)}\\nSD: {np.std(accuracy_before_txt_user_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4bd43b4-96d5-46f2-aa56-4dd112f9f76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance in post-test (TB condition)\n",
      "Mean: 0.8080000000000002\n",
      "SD: 0.23137847782367313\n"
     ]
    }
   ],
   "source": [
    "## Test performance in post-test (TB condition)\n",
    "## collect participants accuracy post viewing TEXTBOOKS\n",
    "true_cnt, total_cnt = 0, 0\n",
    "accuracy_after_txt_user = {}\n",
    "for idx, row in df.iterrows():\n",
    "    if row['Finished'] == 0:\n",
    "        continue\n",
    "    user_id = str(int(row['Q2.4'])).strip()\n",
    "    if user_id not in accuracy_after_txt_user.keys():\n",
    "        accuracy_after_txt_user[user_id] = 0\n",
    "    if len(users[user_id]) <= 3:\n",
    "        users[user_id].append({})\n",
    "    for b_blk_id in before_blks_txt:\n",
    "        sample_id = f\"{b_blk_id}_TB_Aft\"\n",
    "        if sample_id not in users[user_id][3].keys():\n",
    "            users[user_id][3][sample_id] = []\n",
    "        for ques_idx, a_ques_id in enumerate(after_ids_txt):\n",
    "            ans = int(row[f'Q{b_blk_id+1}.{a_ques_id}'])\n",
    "            gt = answer_ids[b_blk_id+1][ques_idx]\n",
    "            if ans == gt:\n",
    "                users[user_id][3][sample_id].append(1)\n",
    "                accuracy_after_txt_user[user_id] += 1\n",
    "                true_cnt += 1\n",
    "            else:\n",
    "                users[user_id][3][sample_id].append(0)\n",
    "            total_cnt += 1\n",
    "    users[user_id].extend([int(row['Q15.2_1']), \n",
    "                           int(row['Q15.3_1']), \n",
    "                           int(row['Q15.4_1']),\n",
    "                           int(row['Q16.2_1']), \n",
    "                           int(row['Q16.3_1']), \n",
    "                           int(row['Q16.4_1']),])\n",
    "\n",
    "print(f\"Test performance in post-test (TB condition)\")\n",
    "accuracy_after_txt_user_list = np.array(list(accuracy_after_txt_user.values()))/10\n",
    "print(f\"Mean: {np.mean(accuracy_after_txt_user_list)}\\nSD: {np.std(accuracy_after_txt_user_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae03552",
   "metadata": {},
   "source": [
    "##### Step3: Performing Linear Mixed-Effects Model (LMM) on Aggregated Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9054886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   participant gender language_proficiency music_proficiency condition  \\\n",
      "0            1      1                    2                 2        TB   \n",
      "1            1      1                    2                 2        SB   \n",
      "2            1      1                    2                 2        TB   \n",
      "3            1      1                    2                 2        SB   \n",
      "4            2      1                    2                 1        TB   \n",
      "..         ...    ...                  ...               ...       ...   \n",
      "95          28      1                    2                 2        SB   \n",
      "96          29      2                    1                 1        TB   \n",
      "97          29      2                    1                 1        SB   \n",
      "98          29      2                    1                 1        TB   \n",
      "99          29      2                    1                 1        SB   \n",
      "\n",
      "    difficulty  accuracy_before  accuracy_after  order  pleasure  arousal  \\\n",
      "0            8              0.6             0.8      1         3        3   \n",
      "1            1              1.0             1.0      2         7        7   \n",
      "2            2              0.6             0.6      4         3        3   \n",
      "3            6              0.4             0.6      3         7        7   \n",
      "4            8              0.6             1.0      1         4        4   \n",
      "..         ...              ...             ...    ...       ...      ...   \n",
      "95           6              0.4             0.6      3         8        3   \n",
      "96           8              0.4             1.0      1         8        5   \n",
      "97           1              0.6             0.8      2         7        5   \n",
      "98           2              0.0             1.0      4         8        5   \n",
      "99           6              0.2             0.8      3         7        5   \n",
      "\n",
      "    dominance  improvement  \n",
      "0           5          0.2  \n",
      "1           5          0.0  \n",
      "2           5          0.0  \n",
      "3           5          0.2  \n",
      "4           8          0.4  \n",
      "..        ...          ...  \n",
      "95          9          0.2  \n",
      "96          8          0.6  \n",
      "97          6          0.2  \n",
      "98          8          1.0  \n",
      "99          6          0.6  \n",
      "\n",
      "[100 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "## Structure data points to meet the format requirements of LMM\n",
    "\n",
    "# Prepare an empty list to store rows\n",
    "rows = []\n",
    "\n",
    "id2difficulty = {7: 8, 9: 1, 11: 6, 13: 2}\n",
    "id2order = {7: 1, 9: 2, 11: 3, 13: 4}\n",
    "\n",
    "poem_conds = {\"9_SB\", \"11_SB\", \"7_TB\", \"13_TB\"}\n",
    "\n",
    "# Loop through the dictionary\n",
    "for user_id, details in users.items():\n",
    "    gender, language_proficiency, music_proficiency, _, p_sb, a_sb, d_sb, p_tb, a_tb, d_tb = details\n",
    "\n",
    "    for poem_cond in poem_conds:\n",
    "        poem_id, material = poem_cond.split(\"_\")\n",
    "        acc_bef = sum(list(users[user_id][3][f\"{poem_cond}_Bef\"]))/5\n",
    "        acc_aft = sum(list(users[user_id][3][f\"{poem_cond}_Aft\"]))/5\n",
    "        difficulty = id2difficulty[int(poem_id)]\n",
    "        order = id2order[int(poem_id)]\n",
    "        if material == \"TB\":\n",
    "            pleasure, arousal, dominance = p_tb, a_tb, d_tb\n",
    "        elif material == \"SB\":\n",
    "            pleasure, arousal, dominance = p_sb, a_sb, d_sb\n",
    "        else:\n",
    "            print(\"OUT OF BOUNDARY\")\n",
    "\n",
    "        rows.append([user_id, gender, language_proficiency, music_proficiency, \n",
    "                     f\"{material}\", int(difficulty), acc_bef, acc_aft, order, pleasure, arousal, dominance])\n",
    "\n",
    "# Convert list to DataFrame\n",
    "df_long = pd.DataFrame(rows, \n",
    "    columns=[\"participant\", \"gender\", \"language_proficiency\", \"music_proficiency\", \n",
    "             \"condition\", \"difficulty\", \"accuracy_before\", \"accuracy_after\", \"order\", \"pleasure\", \"arousal\", \"dominance\"])\n",
    "\n",
    "# Compute improvement score\n",
    "df_long[\"improvement\"] = df_long[\"accuracy_after\"] - df_long[\"accuracy_before\"]\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1980c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Mixed Linear Model Regression Results\n",
      "==========================================================================\n",
      "Model:                   MixedLM      Dependent Variable:      improvement\n",
      "No. Observations:        100          Method:                  REML       \n",
      "No. Groups:              25           Scale:                   0.0292     \n",
      "Min. group size:         4            Log-Likelihood:          10.0456    \n",
      "Max. group size:         4            Converged:               Yes        \n",
      "Mean group size:         4.0                                              \n",
      "--------------------------------------------------------------------------\n",
      "                                Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "--------------------------------------------------------------------------\n",
      "Intercept                        0.959    0.197  4.868 0.000  0.573  1.345\n",
      "condition[T.TB]                  0.011    0.092  0.123 0.902 -0.169  0.192\n",
      "language_proficiency[T.2]       -0.250    0.138 -1.811 0.070 -0.521  0.021\n",
      "language_proficiency[T.3]       -0.192    0.142 -1.349 0.177 -0.471  0.087\n",
      "accuracy_before                 -0.775    0.137 -5.677 0.000 -1.042 -0.507\n",
      "condition[T.TB]:accuracy_before  0.128    0.147  0.872 0.383 -0.160  0.416\n",
      "difficulty                      -0.016    0.010 -1.564 0.118 -0.037  0.004\n",
      "order                           -0.030    0.024 -1.237 0.216 -0.078  0.018\n",
      "Group Var                        0.010    0.040                           \n",
      "==========================================================================\n",
      "\n",
      "Shapiro-Wilk test p-value: ShapiroResult(statistic=np.float64(0.9789218933378997), pvalue=np.float64(0.10951750151035611))\n",
      "Breusch-Pagan test p-value: (np.float64(11.45523401918761), np.float64(0.11995778597155062), np.float64(1.7003207652590668), np.float64(0.1185684946814949))\n",
      "Durbin-Watson statistic: 2.390002019591736\n",
      "Random effect variance: 0.009737966347970382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2237: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# Create the improvement column if not already created\n",
    "df_long[\"improvement\"] = df_long[\"accuracy_after\"] - df_long[\"accuracy_before\"]\n",
    "# df_long['condition'] = pd.Categorical(df_long['condition'], categories=['TB', 'SB'], ordered=True)\n",
    "\n",
    "# Mixed linear model for improvement including all relevant factors\n",
    "# Dependent variable: improvement\n",
    "# Independent variables: test condition (interacts with) pre-test acc, language proficiency, difficulty level of poems, order of poems\n",
    "model_combined = smf.mixedlm(\n",
    "    \"improvement ~ condition * accuracy_before + language_proficiency + difficulty + order\",  # Outcome: improvement\n",
    "    df_long,\n",
    "    groups=df_long[\"participant\"],  # Random intercept for each participant\n",
    "    re_formula=\"1\"  # Random intercept for each participant\n",
    ")\n",
    "\n",
    "# Fit the LMM model\n",
    "result_combined = model_combined.fit()\n",
    "\n",
    "# Save the residuals of LMM to perform assumption diagnosis\n",
    "residuals = np.array(result_combined.resid)\n",
    "\n",
    "# Display the results\n",
    "print(result_combined.summary())\n",
    "\n",
    "## Assumption diagnoses\n",
    "\n",
    "# 1. **Normality of Residuals**\n",
    "# Shapiro-Wilk test for normality\n",
    "shapiro_test = stats.shapiro(residuals)\n",
    "print(f\"Shapiro-Wilk test p-value: {shapiro_test}\")\n",
    "\n",
    "# 2. **Homogeneity of Variance (Homoscedasticity)**\n",
    "# Breusch-Pagan test for homoscedasticity\n",
    "# _, pval, _, _ = het_breuschpagan(residuals, result_combined.model.exog)\n",
    "het_results = het_breuschpagan(residuals, result_combined.model.exog)\n",
    "print(f\"Breusch-Pagan test p-value: {het_results}\")\n",
    "\n",
    "# 3. **Independence of Residuals**\n",
    "# Durbin-Watson test for autocorrelation\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print(f\"Durbin-Watson statistic: {dw_stat}\")\n",
    "\n",
    "# 4. **Random Effects Structure**\n",
    "# Extract random effects variance\n",
    "random_effect_variance = result_combined.cov_re.iloc[0, 0]\n",
    "print(f\"Random effect variance: {random_effect_variance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
